{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started\n",
    "\n",
    "1. Create a new GitHub repository, call it something like `time_series_basic` or `time_series_forecasting_basic` etc\n",
    "2. Clone the repository to a local folder on your workstation\n",
    "3. Change into the folder\n",
    "4. Activate the `greyatom` environment: `source activate greyatom`\n",
    "5. Start jupyter notebook: `jupyter notebook`\n",
    "6. Create two notebooks\n",
    "    - `scratchpad.ipynb`\n",
    "    - `daily_temperature_prediction.ipynb`\n",
    "7. Add, commit and push the changes to the remote repo\n",
    "\n",
    "> git add .\n",
    "\n",
    "> git commit -m 'adds notebooks'\n",
    "\n",
    "> git push"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is Time Series Data\n",
    "\n",
    "* A time series is a series of data points indexed (or listed or graphed) in time order\n",
    "* Most commonly, a time series is a sequence taken at successive equally spaced points in time\n",
    "* Time series forecasting is the use of a model to predict future values based on previously observed values\n",
    "* Time Series Forecasting vs Supervised Machine Learning\n",
    "\n",
    "Important feature of most time series is that observations close together in time tend to be correlated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Nomenclature\n",
    "\n",
    "* Current time is $t$\n",
    "* Times in the past are negative (relative to current time) - $t_{-1}$, $t_{-2}$\n",
    "* $\\ldots t_{-1}$, $t_{-2}$, $t$, $t_{1}$, $t_{2} \\ldots$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate vs Multivariate\n",
    "\n",
    "* **Univariate Time Series**: These are datasets where only a single variable is observed at each time, such as temperature each hour. The example in the previous section is a univariate time series dataset.\n",
    "* **Multivariate Time Series**: These are datasets where two or more variables are observed at each time.\n",
    "\n",
    "Multivariate data is often more difficult to work with. It is harder to model and often many of the classical methods do not perform well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descriptive vs Predictive Analysis\n",
    "\n",
    "* In **time series analysis**, a time series is modeled to determine its components in terms of\n",
    "    - seasonal patterns\n",
    "    - trends\n",
    "    - relation to external factors\n",
    "    - basline\n",
    "    - noise\n",
    "    - etc\n",
    "* In contrast, **time series forecasting** uses the information in a time series (perhaps with additional information) to forecast future values of that series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples of Time Series Forecasting\n",
    "\n",
    "* Forecasting whether an EEG trace in seconds indicates a patient is having a seizure or not.\n",
    "* Forecasting the closing price of a stock each day.\n",
    "* Forecasting the birth rate at all hospitals in a city each year.\n",
    "* Forecasting product sales in units sold each day for a store.\n",
    "* Forecasting the number of passengers through a train station each day."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Typical Pre-processing for Time Series Data\n",
    "\n",
    "* **Missing**: Perhaps there are gaps or missing data that need to be interpolated or imputed.\n",
    "* **Outliers**: Perhaps there are corrupt or extreme outlier values that need to be identified and handled.\n",
    "* **Frequency**: Perhaps data is provided at a frequency that is too high to model or is unevenly spaced through time requiring resampling for use in some models.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Components of Time Series\n",
    "\n",
    "Time series analysis provides a body of techniques to better understand a dataset. Perhaps the most useful of these is the decomposition of a time series into 4 constituent parts:\n",
    "\n",
    "* **Level**: The baseline value for the series if it were a straight line.\n",
    "* **Trend**: The optional and often linear increasing or decreasing behavior of the series over time.\n",
    "* **Seasonality**: The optional repeating patterns or cycles of behavior over time.\n",
    "* **Noise**: The optional variability in the observations that cannot be explained by the model.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series as a Supervised Machine Learning problem\n",
    "\n",
    "* The Task: given a sequence of numbers for a time series dataset, we have to reformulate the data to look like a supervised machine learning problem\n",
    "* How: by using previous time steps as input variables, and using the next time step as the output variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate example\n",
    "\n",
    "| time | measure |\n",
    "|------|---------|\n",
    "| 1 |  100 |\n",
    "| 2 |  110 |\n",
    "| 3 |  108 |\n",
    "| 4 |  115 |\n",
    "| 5 |  120 |\n",
    "\n",
    "becomes\n",
    "\n",
    "| X | y |\n",
    "|------|---------|\n",
    "| ? |  100 |\n",
    "| 100 |  110 |\n",
    "| 110 |  108 |\n",
    "| 108 |  115 |\n",
    "| 115 |  120 |\n",
    "| 120 |  ? |\n",
    "\n",
    "* We can see that the previous time step is the input (X) and the next time step is the output (y) in our supervised learning problem.\n",
    "* We can see that the order between the observations is preserved, and must continue to be preserved when using this dataset to train a supervised model.\n",
    "* We can see that we have no previous value that we can use to predict the first value in the sequence. We will delete this row as we cannot use it.\n",
    "* We can also see that we do not have a known next value to predict for the last value in the sequence. We may want to delete this value while training our supervised model also.\n",
    "\n",
    "The use of prior time steps to predict the next time step is called the **sliding window** or **window** method. In statistics and time series analysis, this is called a **lag** or **lag method**. The number of previous time steps is called the window width or size of the lag. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate example\n",
    "\n",
    "In the following example, we want to predict `measure2`:\n",
    "\n",
    "| time | measure1 | measure2 |\n",
    "|------|----------|----------|\n",
    "| 1 | 0.2 | 88 |\n",
    "| 2 | 0.5 | 89 |\n",
    "| 3 | 0.7 | 87 |\n",
    "| 4 | 0.4 | 88 |\n",
    "| 5 | 1.0 | 90 |\n",
    "\n",
    "becomes\n",
    "\n",
    "| $X_1$ | $X_2$ | $X_3$ | y |\n",
    "|-------|-------|-------|---|\n",
    "| ?   | ?  | 0.2 | 88 |\n",
    "| 0.2 | 88 | 0.5 | 89 |\n",
    "| 0.5 | 89 | 0.7 | 87 |\n",
    "| 0.7 | 87 | 0.4 | 88 |\n",
    "| 0.4 | 88 | 1.0 | 90 |\n",
    "| 1.0 | 90 | ?   | ?  |\n",
    "\n",
    "* What is the value of lag?\n",
    "* What is the value of window width?\n",
    "* How was $X_1$ constructed?\n",
    "* How was $X_2$ constructed?\n",
    "* How was $X_3$ constructed?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## One-step vs Multi-step\n",
    "\n",
    "* One-Step Forecast: This is where the next time step (t+1) is predicted.\n",
    "* Multi-Step Forecast: This is where two or more future time steps are to be predicted.\n",
    "\n",
    "| time | measure |\n",
    "|------|---------|\n",
    "| 1 |  100 |\n",
    "| 2 |  110 |\n",
    "| 3 |  108 |\n",
    "| 4 |  115 |\n",
    "| 5 |  120 |\n",
    "| 6 |   ?  |\n",
    "| 7 |   ?  |\n",
    "\n",
    "becomes\n",
    "\n",
    "| X    | $y_1$   | $y_2$   |\n",
    "|------|---------|---------|\n",
    "|  ?  |  100 |  110 |\n",
    "| 100 |  110 |  108 |\n",
    "| 110 |  108 |  115 |\n",
    "| 108 |  115 |  120 |\n",
    "| 115 |  120 |   ?  |\n",
    "| 120 |   ?  |   ?  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Time Series Data\n",
    "\n",
    "## The Dataset\n",
    "\n",
    "* We will use the Daily Female Births Dataset as an example. This dataset describes the number of daily female births in California in 1959.\n",
    "    - You can find it inside the `data` subfolder\n",
    "    - You can download it from https://datamarket.com/data/set/235k/daily-total-female-births-in-california-1959#!ds=235k&display=line\n",
    "\n",
    "![](./images/ts01.png)\n",
    "\n",
    "## Load Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Date\n",
       "1959-01-01    35\n",
       "1959-01-02    32\n",
       "1959-01-03    30\n",
       "1959-01-04    31\n",
       "1959-01-05    44\n",
       "Name: Daily total female births in California, 1959, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas import Series\n",
    "\n",
    "series = Series.from_csv('./data/female_births.csv', header=0)\n",
    "print(type(series))\n",
    "series.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* You can see that each row has an associated date.\n",
    "    - This is in fact not a column, but instead a time index for value.\n",
    "    - As an index, there can be multiple values for one time, and values may be spaced evenly or unevenly across times.\n",
    "* The main function for loading CSV data in Pandas is `read_csv()`. We can use this to load the time series as a Series object, instead of a DataFrame, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "Date\n",
      "1959-01-01    35\n",
      "1959-01-02    32\n",
      "1959-01-03    30\n",
      "1959-01-04    31\n",
      "1959-01-05    44\n",
      "Name: Daily total female births in California, 1959, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from pandas import read_csv\n",
    "series = read_csv('./data/female_births.csv', \n",
    "                  header=0, parse_dates=[0], index_col=0, squeeze=True)\n",
    "print(type(series))\n",
    "print(series.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **header=0**: We must specify the header information at row 0.\n",
    "* **parse dates=[0]**: We give the function a hint that data in the first column contains dates that need to be parsed. This argument takes a list, so we provide it a list of one element, which is the index of the first column.\n",
    "* **index_col=0**: We give a hint that the first column contains the index information for the time series.\n",
    "* **squeeze=True**: We give a hint that we only have one data column and that we are interested in a Series and not a DataFrame.\n",
    "* In this example, the date format has been inferred, and this works in most cases.\n",
    "    - In those few cases where it does not, specify your own date parsing function and use the `date_parser` argument.\n",
    "    \n",
    "## Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "1959-01-01    35\n",
       "1959-01-02    32\n",
       "1959-01-03    30\n",
       "1959-01-04    31\n",
       "1959-01-05    44\n",
       "1959-01-06    29\n",
       "1959-01-07    45\n",
       "1959-01-08    43\n",
       "1959-01-09    38\n",
       "1959-01-10    27\n",
       "Name: Daily total female births in California, 1959, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from pandas import read_csv\n",
    "series = read_csv('../data/female_births.csv', \n",
    "                  header=0, parse_dates=[0], index_col=0, squeeze=True)\n",
    "\n",
    "series.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "1959-12-27    37\n",
       "1959-12-28    52\n",
       "1959-12-29    48\n",
       "1959-12-30    55\n",
       "1959-12-31    50\n",
       "Name: Daily total female births in California, 1959, dtype: int64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(365,)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "365"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    365.000000\n",
       "mean      41.980822\n",
       "std        7.348257\n",
       "min       23.000000\n",
       "25%       37.000000\n",
       "50%       42.000000\n",
       "75%       46.000000\n",
       "max       73.000000\n",
       "Name: Daily total female births in California, 1959, dtype: float64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.977587954880505"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.skew()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Feature Engineering\n",
    "\n",
    "Time Series data must be re-framed as a supervised learning dataset before we can start using machine learning algorithms. We will look at three classes of features that we can create from our time series dataset:\n",
    "\n",
    "* **Date Time Features**: these are components of the time step itself for each observation\n",
    "* **Lag Features**: these are values at prior time steps\n",
    "* **Window Features**: these are a summary of values over a fixed window of prior time steps\n",
    "\n",
    "## The Dataset\n",
    "\n",
    "* This dataset describes the minimum daily temperatures over 10 years (1981-1990) in the city Melbourne, Australia. The units are in degrees Celsius and there are 3650 observations.\n",
    "    - You can find it inside the `data` subfolder\n",
    "    - You can download it from https://datamarket.com/data/set/2324/daily-minimum-temperatures-in-melbourne-australia-1981-1990#!ds=2324&display=line\n",
    "\n",
    "![](./images/ts03.png)\n",
    "\n",
    "### Load Data\n",
    "\n",
    "**Swtich to your time-series-forecasting notebook**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "1981-01-01    20.7\n",
       "1981-01-02    17.9\n",
       "1981-01-03    18.8\n",
       "1981-01-04    14.6\n",
       "1981-01-05    15.8\n",
       "Name: Daily minimum temperatures in Melbourne, Australia, 1981-1990, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series = read_csv('../data/daily_temp.csv', \n",
    "                  header=0, parse_dates=[0], index_col=0, squeeze=True)\n",
    "series.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Daily minimum temperatures in Melbourne, Australia, 1981-1990</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1981-01-01</th>\n",
       "      <td>20.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-01-02</th>\n",
       "      <td>17.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-01-03</th>\n",
       "      <td>18.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-01-04</th>\n",
       "      <td>14.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-01-05</th>\n",
       "      <td>15.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Daily minimum temperatures in Melbourne, Australia, 1981-1990\n",
       "Date                                                                    \n",
       "1981-01-01                                               20.7           \n",
       "1981-01-02                                               17.9           \n",
       "1981-01-03                                               18.8           \n",
       "1981-01-04                                               14.6           \n",
       "1981-01-05                                               15.8           "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series = read_csv('../data/daily_temp.csv', \n",
    "                  header=0, parse_dates=[0], index_col=0)\n",
    "series.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Date Time Features\n",
    "\n",
    "Add day, month and year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year  month  day temperature\n",
      "0     0      1    1        20.7\n",
      "1     0      1    2        17.9\n",
      "2     0      1    3        18.8\n",
      "3     0      1    4        14.6\n",
      "4     0      1    5        15.8\n"
     ]
    }
   ],
   "source": [
    "from pandas import Series\n",
    "from pandas import DataFrame\n",
    "series = Series.from_csv('../data/daily_temp.csv', header=0)\n",
    "\n",
    "dataframe = DataFrame()\n",
    "\n",
    "dataframe['year'] = [series.index[i].year-1981 for i in range(len(series))] \n",
    "dataframe['month'] = [series.index[i].month for i in range(len(series))] \n",
    "dataframe['day'] = [series.index[i].day for i in range(len(series))] \n",
    "dataframe['temperature'] = [series[i] for i in range(len(series))] \n",
    "\n",
    "print(dataframe.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some more examples (which of the following are going to be useful?):\n",
    "\n",
    "* Minutes elapsed for the day\n",
    "* Hour of day\n",
    "* Business hours or not\n",
    "* Weekend or not\n",
    "* Season of the year\n",
    "* Business quarter of the year\n",
    "* Daylight savings or not\n",
    "* Public holiday or not\n",
    "* Leap year or not\n",
    "\n",
    "## Adding Lag features\n",
    "\n",
    "* The Pandas library provides the `shift()` function to help create these shifted or lag features from a time series dataset.\n",
    "* Shifting the dataset by 1 creates the t column, adding a NaN (unknown) value for the first row\n",
    "* The time series dataset without a shift represents the t+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      t   t+1\n",
      "0   NaN  20.7\n",
      "1  20.7  17.9\n",
      "2  17.9  18.8\n",
      "3  18.8  14.6\n",
      "4  14.6  15.8\n"
     ]
    }
   ],
   "source": [
    "from pandas import Series\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "series = Series.from_csv('../data/daily_temp.csv', header=0) \n",
    "\n",
    "temps = DataFrame(series.values)\n",
    "dataframe = concat([temps.shift(1), temps], axis=1)\n",
    "dataframe.columns = ['t', 't+1']\n",
    "print(dataframe.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can expand the window width and include more lagged features. Let us include the last 3 observed values to predict the value at the next time step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    t-2   t-1     t   t+1\n",
      "0   NaN   NaN   NaN  20.7\n",
      "1   NaN   NaN  20.7  17.9\n",
      "2   NaN  20.7  17.9  18.8\n",
      "3  20.7  17.9  18.8  14.6\n",
      "4  17.9  18.8  14.6  15.8\n"
     ]
    }
   ],
   "source": [
    "from pandas import Series\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "series = Series.from_csv('../data/daily_temp.csv', header=0) \n",
    "\n",
    "temps = DataFrame(series.values)\n",
    "dataframe = concat([temps.shift(3), temps.shift(2), temps.shift(1), temps], axis=1)\n",
    "dataframe.columns = ['t-2', 't-1', 't', 't+1']\n",
    "print(dataframe.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can include lag values from past week, month or year as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task\n",
    "\n",
    "1. For the entire datatset, add the following features\n",
    "    - Day of the month\n",
    "    - Month of the year\n",
    "    - Year - 1981\n",
    "    - Day of the year\n",
    "        * write a custom function which computes day of the year from day of the month and month of year\n",
    "        * apply the function in list comprehension\n",
    "    - Add $lag_{1}$, $lag_{2}$, $lag_{3}$, $lag_{4}$, $lag_{5}$ features\n",
    "2. Split the dataset into two parts\n",
    "    - $1^{st}$ 9 years (training set)\n",
    "    - the last (tenth) year (test set)\n",
    "3. Write a function to fit a model to your training set (return model as an output)\n",
    "4. Write a function to predict the model's performance on the test set"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
